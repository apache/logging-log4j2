////
    Licensed to the Apache Software Foundation (ASF) under one or more
    contributor license agreements.  See the NOTICE file distributed with
    this work for additional information regarding copyright ownership.
    The ASF licenses this file to You under the Apache License, Version 2.0
    (the "License"); you may not use this file except in compliance with
    the License.  You may obtain a copy of the License at

         http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
////

= Appenders

Appenders are responsible for delivering log events to their destination.
Every Appender must implement the
link:../javadoc/log4j-core/org/apache/logging/log4j/core/Appender.html[`Appender`]
interface.

While not strictly required by the Log4j Core architecture, most appenders inherit from
link:../javadoc/log4j-core/org/apache/logging/log4j/core/appender/AbstractAppender.html[`AbstractAppender`]
and:

* delegate the filtering of log events to an implementation of
link:../javadoc/log4j-core/org/apache/logging/log4j/core/Filter.html[`Filter`].
See xref:manual/filters.adoc[] for more information.
* delegate the formatting of log events to an implementation of
link:../javadoc/log4j-core/org/apache/logging/log4j/core/Layout.html[`Layout`].
See xref:manual/layouts.adoc[] for more information.
* only directly handle the writing of log event data to the target destination.

Appenders always have a name so that they can be referenced from a
xref:manual/configuration.adoc#configuring-loggers[logger configuration].

[#commons-concerns]
== Common concerns

[#buffering]
=== Buffering

Appenders that use stream-like resources (such as files, TCP connections) have an internal
https://docs.oracle.com/javase/{java-target-version}/docs/api/java/nio/ByteBuffer.html[`ByteBuffer`]
that can be used to format each log event, before sending it to the underlying resource.
The buffer is used if:

* the
xref:manual/systemproperties.adoc#log4j2.enableDirectEncoders[`log4j2.enableDirectEncoders`]
configuration property is enabled,
* or the <<bufferedIo,`bufferedIo`>> configuration attribute is enabled.

The buffer is flushed to the underlying resource on three occasions:

* if the buffer is full.
* at the end of each log event batch, if
xref:manual/async.adoc[asynchronous loggers]
or
xref:manual/appenders/delegating.adoc#AsyncAppender[appenders]
are used.
* at the end of each log event, if the
<<immediateFlush,`immediateFlush`>>
configuration attribute is `true`.

These configuration attributes are shared by multiple appenders:

[#bufferSize]
==== `bufferSize`

[cols="1h,5"]
|===
| Type
| `int`

| Default value
| xref:manual/systemproperties.adoc#log4j2.encoderByteBufferSize[`log4j2.encoderByteBufferSize`]
|===

This configuration attribute specifies the size of the `ByteBuffer` used by the appender.

[#bufferedIo]
==== `bufferedIo`

[cols="1h,5"]
|===
| Type          | `boolean`
| Default value | `true`
|===

If set to `true`, Log4j Core will use an internal `ByteBuffer` to store log events before sending them.

If the xref:manual/systemproperties.adoc#log4j2.enableDirectEncoders[`log4j2.enableDirectEncoders`] configuration property is set to `true`, the internal `ByteBuffer` will always be used.

[#immediateFlush]
==== `immediateFlush`

[cols="1h,5"]
|===
| Type          | `boolean`
| Default value | `true`
|===

If set to `true`, Log4j will flush Log4j Core and Java buffers at the end of each event:

* the internal `ByteBuffer` of the appender will be flushed.
* for appenders based on Java's
https://docs.oracle.com/javase/{java-target-version}/docs/api/java/io/OutputStream.html[`OutputStream`]
a call to the `OutputStream.flush()` method will be performed.

[IMPORTANT]
====
This setting only guarantees that a byte representation of the log event is passed to the operating system.
It does not ensure that the operating system writes the event to the underlying storage.
====

[TIP]
====
If you are using
xref:manual/async.adoc[asynchronous loggers]
or
xref:manual/appenders/delegating.adoc#AsyncAppender[appenders], you can set this attribute to `false`.
Log4j Core will still flush the internal buffer, whenever the log event queue becomes empty.
====

[#exception-handling]
=== Exception handling

By default, Log4j Core uses xref:manual/status-logger.adoc[] to report exceptions that occur in appenders.
This behavior can be changed using the following configuration property:

[#ignoreExceptions]
==== `ignoreExceptions`

[cols="1h,5"]
|===
| Type          | `boolean`
| Default value | `true`
|===

If `false` logging exceptions will be forwarded to the caller.
Otherwise, they will be logged using xref:manual/status-logger.adoc[].

[TIP]
====
If logging is important for your business, consider using a
xref:manual/appenders/delegating.adoc#FailoverAppender[`Failover` Appender]
to redirect log events to a different appender in case of exceptions.
====

[#runtime-evaluation]
=== Runtime evaluation of attributes

The following configuration attributes are also evaluated at runtime, so can contain escaped `$$+{...}+` property substitution expressions.

.List of attributes evaluated at runtime
[cols="1,1,1,1"]
|===
| Component | Parameter | Event type | Evaluation context

| <<HttpAppender,HTTP Appender>>
| <<HttpAppender-element-headers,`Property/value`>>
| Log event
| xref:manual/lookups.adoc#global-context[_global_]

| <<KafkaAppender,Kafka Appender>>
| <<KafkaAppender-attr-key,`key`>>
| Log event
| xref:manual/lookups.adoc#global-context[_global_]

| <<NoSQLAppender,NoSQL Appender>>
| <<NoSqlAppender-element-keyValuePairs,`KeyValuePair/value`>>
| Log event
| xref:manual/lookups.adoc#global-context[_global_]

| xref:manual/appenders/delegating.adoc#PropertiesRewritePolicy[PropertiesRewrite Policy]
| xref:manual/appenders/delegating.adoc#PropertiesRewritePolicy-element-Property[`Property/value`]
| Log event
| xref:manual/lookups.adoc#global-context[_global_]

| xref:manual/appenders/delegating.adoc#Routes[Routes Container]
| xref:manual/appenders/delegating.adoc#Routes-attr-pattern[`pattern`]
| Log event
| xref:manual/lookups.adoc#event-context[_log event_]

| xref:manual/appenders/rolling-file.adoc[Rolling File Appenders]
| xref:manual/appenders/rolling-file.adoc#attr-filePattern[`filePattern`]
| Rollover
| xref:manual/lookups.adoc#global-context[_global_]

| xref:manual/appenders/rolling-file.adoc#AbstractPathAction[Optional Rollover Actions]
| xref:manual/appenders/rolling-file.adoc#AbstractPathAction-attr-basePath[`basePath`]
| Rollover
| xref:manual/lookups.adoc#global-context[_global_]

|===

The
xref:manual/appenders/delegating.adoc#Route[`Route`]
component of the
xref:manual/appenders/delegating.adoc#RoutingAppender[Routing Appender]
is special: its children are evaluated at runtime, but they are **not** evaluated at configuration time.
Inside the `Route` component you **should not** use escaped `$$+{...}+` property substitution expressions, but only unescaped `$+{...}+` property substitution expressions.

See xref:manual/configuration.adoc#lazy-property-substitution[runtime property substitution] for more details.

[#collection]
== Collection

Log4j bundles several predefined appenders to assist in several common deployment use cases.
They are documented in separate pages based on their target resource:

[#file-appenders]
=== File appenders

File appenders write logs to the filesystem.
They can be further split into:

Single file appenders:::
See xref:manual/appenders/file.adoc[] for details.

Rolling file appenders:::
See xref:manual/appenders/rolling-file.adoc[] for details.

[#delegating-appenders]
=== Delegating appenders

Delegating appenders are intended to decorate other appenders:

xref:manual/appenders/delegating.adoc#AsyncAppender[Asynchronous appender]::
Perform all I/O on a dedicated thread

xref:manual/appenders/delegating.adoc#FailoverAppender[Failover appender]::
Provide a backup appender in case an appender fails

xref:manual/appenders/delegating.adoc#RewriteAppender[Rewrite appender]::
Modify log events prior to delivering them to the target

xref:manual/appenders/delegating.adoc#RoutingAppender[Routing appender]::
Dynamically choose a different appender for each log event

See xref:manual/appenders/delegating.adoc[] for details.

[#CassandraAppender]
=== CassandraAppender

The CassandraAppender writes its output to an
https://cassandra.apache.org/_/index.html[Apache Cassandra]
database.
A keyspace and table must be configured ahead of time, and the columns of that table are mapped in a configuration file.
Each column can specify either a xref:manual/pattern-layout.adoc[]https://logging.apache.org/log4j/2.x/manual/layouts.html#PatternLayout[StringLayout] (e.g., a PatternLayout) along with an optional conversion type, or only a conversion type for `org.apache.logging.log4j.spi.ThreadContextMap` or
`org.apache.logging.log4j.spi.ThreadContextStack` to store the MDC or NDC in a map or list column respectively.
A conversion type compatible with `java.util.Date` will use the log event timestamp converted to that type (e.g., use `java.util.Date` to fill a
`timestamp` column type in Cassandra).

.CassandraAppender Parameters
[cols="1,1,3",options="header"]
|===
| Parameter Name | Type | Description

| batched
| boolean
| Whether or not to use batch statements to write log messages to Cassandra. By default, this is `false`.

| batchType
| https://docs.datastax.com/en/drivers/java/3.0/com/datastax/driver/core/BatchStatement.Type.html[BatchStatement.Type]
| The batch type to use when using batched writes. By default, this is `LOGGED`.

| bufferSize
| int
| The number of log messages to buffer or batch before writing. By default, no buffering is done.

| clusterName
| String
| The name of the Cassandra cluster to connect to.

| columns
| ColumnMapping[]
| A list of column mapping configurations. Each column must specify a column name. Each column can
have a conversion type specified by its fully qualified class name. By default, the conversion type is
`String`. If the configured type is assignment-compatible with
ReadOnlyStringMap /
ThreadContextMap or
ThreadContextStack,
then that column will be populated with the MDC or NDC respectively. If the configured type is
assignment-compatible with `java.util.Date`, then the log timestamp will be converted to
that configured date type. If a `literal` attribute is given, then its value will be used as
is in the `INSERT` query without any escaping. Otherwise, the layout or pattern specified
will be converted into the configured type and stored in that column.

| contactPoints
| SocketAddress[]
| A list of hosts and ports of Cassandra nodes to connect to. These must be valid hostnames or IP
addresses. By default, if a port is not specified for a host or it is set to 0, then the default
Cassandra port of 9042 will be used. By default, `localhost:9042` will be used.

| filter
| Filter
| A Filter to determine if the event should be handled by this Appender. More than one Filter may be used
by using a CompositeFilter.

| ignoreExceptions
| boolean
| The default is `true`, causing exceptions encountered while appending events to be
internally logged and then ignored. When set to `false` exceptions will be propagated to the
caller, instead. You must set this to `false` when wrapping this Appender in a
FailoverAppender.

| keyspace
| String
| The name of the keyspace containing the table that log messages will be written to.

| name
| String
| The name of the Appender.

| password
| String
| The password to use (along with the username) to connect to Cassandra.

| table
| String
| The name of the table to write log messages to.

| useClockForTimestampGenerator
| boolean
| Whether or not to use the configured `org.apache.logging.log4j.core.util.Clock` as a
TimestampGenerator. By default, this is `false`.

| username
| String
| The username to use to connect to Cassandra. By default, no username or password is used.

| useTls
| boolean
| Whether or not to use TLS/SSL to connect to Cassandra. This is `false` by default.
|===

Here is an example `CassandraAppender` configuration:

[source,xml]
----
<Configuration name="CassandraAppenderTest">
  <Appenders>
    <Cassandra name="Cassandra" clusterName="Test Cluster" keyspace="test" table="logs" bufferSize="10" batched="true">
      <SocketAddress host="localhost" port="9042"/>
      <ColumnMapping name="id" pattern="%uuid{TIME}" type="java.util.UUID"/>
      <ColumnMapping name="timeid" literal="now()"/>
      <ColumnMapping name="message" pattern="%message"/>
      <ColumnMapping name="level" pattern="%level"/>
      <ColumnMapping name="marker" pattern="%marker"/>
      <ColumnMapping name="logger" pattern="%logger"/>
      <ColumnMapping name="timestamp" type="java.util.Date"/>
      <ColumnMapping name="mdc" type="org.apache.logging.log4j.spi.ThreadContextMap"/>
      <ColumnMapping name="ndc" type="org.apache.logging.log4j.spi.ThreadContextStack"/>
    </Cassandra>
  </Appenders>
  <Loggers>
    <Logger name="org.apache.logging.log4j.cassandra" level="DEBUG">
      <AppenderRef ref="Cassandra"/>
    </Logger>
    <Root level="ERROR"/>
  </Loggers>
</Configuration>
----

This example configuration uses the following table schema:

[source,sql]
----
CREATE TABLE logs (
    id timeuuid PRIMARY KEY,
    timeid timeuuid,
    message text,
    level text,
    marker text,
    logger text,
    timestamp timestamp,
    mdc map<text,text>,
    ndc list<text>
);
----

[id=consoleappender]
=== [[ConsoleAppender]] ConsoleAppender

As one might expect, the ConsoleAppender writes its output to either
`System.out` or `System.err` with `System.out` being the default target.
A Layout must be provided to format the LogEvent.

.ConsoleAppender Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|filter |Filter |A Filter to determine if the event should be handled by
this Appender. More than one Filter may be used by using a
CompositeFilter.

|layout |Layout |The Layout to use to format the LogEvent. If no layout
is supplied the default pattern layout of "%m%n" will be used.

|follow |boolean |Identifies whether the appender honors reassignments
of `System.out` or `System.err` via `System.setOut` or `System.setErr` made
after configuration. Note that the follow attribute cannot be used with
Jansi on Windows. Cannot be used with `direct`.

|direct |boolean |Write directly to `java.io.FileDescriptor` and bypass
`java.lang.System.out/.err`. Can give up to 10x performance boost when
the output is redirected to a file or other process. Cannot be used with
Jansi on Windows. Cannot be used with `follow`. The output will not respect
`java.lang.System.setOut()/.setErr()` and may get intertwined with other
output to `java.lang.System.out/.err` in a multi-threaded application.
_New since 2.6.2. Be aware that this is a new addition, and it has only
been tested with Oracle JVM on Linux and Windows so far._

|name |String |The name of the Appender.

|ignoreExceptions |boolean |The default is `true`, causing exceptions
encountered while appending events to be internally logged and then
ignored. When set to `false` exceptions will be propagated to the
caller, instead. You must set this to `false` when wrapping this
Appender in a <<FailoverAppender>>.

|target |String |Either "SYSTEM_OUT" or "SYSTEM_ERR". The default is
"SYSTEM_OUT".
|=======================================================================

A typical Console configuration might look like:

[source,xml,prettyprint,linenums]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <Console name="STDOUT" target="SYSTEM_OUT">
      <PatternLayout pattern="%m%n"/>
    </Console>
  </Appenders>
  <Loggers>
    <Root level="error">
      <AppenderRef ref="STDOUT"/>
    </Root>
  </Loggers>
</Configuration>
----


[#FlumeAppender]
=== FlumeAppender

_This is an optional component supplied in a separate jar._

https://flume.apache.org/index.html[Apache Flume] is a distributed, reliable, and available system for efficiently collecting, aggregating, and moving large amounts of log data from many different sources to a centralized data store.
The FlumeAppender takes LogEvents and sends them to a Flume agent as serialized Avro events for consumption.

The Flume Appender supports three modes of operation.

1. It can act as a remote Flume client which sends Flume events via Avro to a Flume Agent configured with an Avro Source.
2. It can act as an embedded Flume Agent where Flume events pass directly into Flume for processing.
3. It can persist events to a local BerkeleyDB data store and then asynchronously send the events to Flume, similar to the embedded Flume Agent but without most of the Flume dependencies.

Usage as an embedded agent will cause the messages to be directly passed to the Flume Channel and then control will be immediately returned to the application.
All interaction with remote agents will occur asynchronously.
Setting the "type" attribute to "Embedded" will force the use of the embedded agent.
In addition, configuring agent properties in the appender configuration will also cause the embedded agent to be used.

.FlumeAppender Parameters
[width="100%",cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|agents |Agent[] |An array of Agents to which the logging events should
be sent. If more than one agent is specified the first Agent will be the
primary and subsequent Agents will be used in the order specified as
secondaries should the primary Agent fail. Each Agent definition
supplies the Agent's host and port. The specification of agents and
properties are mutually exclusive. If both are configured an error will
result.

|agentRetries |integer |The number of times the agent should be retried
before failing to a secondary. This parameter is ignored when
`type="persistent"` is specified (agents are tried once before failing to
the next).

|batchSize |integer |Specifies the number of events that should be sent
as a batch. The default is 1. _This parameter only applies to the Flume
Appender._

|compress |boolean |When set to true the message body will be compressed
using gzip

|connectTimeoutMillis |integer |The number of milliseconds Flume will
wait before timing out the connection.

|dataDir |String |Directory where the Flume write-ahead log should be
written. Valid only when embedded is set to true and Agent elements are
used instead of Property elements.

|filter |Filter |A Filter to determine if the event should be handled by
this Appender. More than one Filter may be used by using a
CompositeFilter.

|eventPrefix |String |The character string to prepend to each event
attribute to distinguish it from MDC attributes. The default is
an empty string.

|flumeEventFactory |FlumeEventFactory |Factory that generates the Flume
events from Log4j events. The default factory is the FlumeAvroAppender
itself.

|layout |Layout |The Layout to use to format the LogEvent. If no layout
is specified RFC5424Layout will be used.

|lockTimeoutRetries |integer |The number of times to retry if a
LockConflictException occurs while writing to Berkeley DB. The default
is 5.

|maxDelayMillis |integer |The maximum number of milliseconds to wait for
batchSize events before publishing the batch.

|mdcExcludes |String |A comma-separated list of mdc keys that should be
excluded from the FlumeEvent. This is mutually exclusive with the
mdcIncludes attribute.

|mdcIncludes |String |A comma-separated list of mdc keys that should be
included in the FlumeEvent. Any keys in the MDC not found in the list
will be excluded. This option is mutually exclusive with the mdcExcludes
attribute.

|mdcRequired |String |A comma-separated list of `mdc` keys that must be
present in the MDC. If a key is not present a LoggingException will be
thrown.

|mdcPrefix |String |A string that should be prepended to each MDC key to distinguish it from event attributes. The default string is
"mdc:".

|name |String |The name of the Appender.

|properties |Property[] a|
One or more Property elements that are used to configure the Flume
Agent. The properties must be configured without the agent name (the
appender name is used for this) and no sources can be configured.
Interceptors can be specified for the source using
"sources.log4j-source.interceptors". All other Flume configuration
properties are allowed. Specifying both Agent and Property elements will
result in an error.

When used to configure in Persistent mode the valid properties are:

1. `keyProvider` to specify the name of the plugin to provide the
secret key for encryption.

|requestTimeoutMillis |integer |The number of milliseconds Flume will
wait before timing out the request.

|ignoreExceptions |boolean |The default is `true`, causing exceptions
encountered while appending events to be internally logged and then
ignored. When set to `false` exceptions will be propagated to the
caller, instead. You must set this to `false` when wrapping this
Appender in a <<FailoverAppender>>.

|type |enumeration |One of "Avro", "Embedded", or "Persistent" to
indicate which variation of the Appender is desired.
|=======================================================================

A sample FlumeAppender configuration that is configured with a primary and a secondary agent compresses the body and formats the body using the RFC5424Layout:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <Flume name="eventLogger" compress="true">
      <Agent host="192.168.10.101" port="8800"/>
      <Agent host="192.168.10.102" port="8800"/>
      <RFC5424Layout enterpriseNumber="18060" includeMDC="true" appName="MyApp"/>
    </Flume>
  </Appenders>
  <Loggers>
    <Root level="error">
      <AppenderRef ref="eventLogger"/>
    </Root>
  </Loggers>
</Configuration>
----

A sample FlumeAppender configuration that is configured with a primary and a secondary agent compresses the body, formats the body using the RFC5424Layout, and persists encrypted events to disk:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <Flume name="eventLogger" compress="true" type="persistent" dataDir="./logData">
      <Agent host="192.168.10.101" port="8800"/>
      <Agent host="192.168.10.102" port="8800"/>
      <RFC5424Layout enterpriseNumber="18060" includeMDC="true" appName="MyApp"/>
      <Property name="keyProvider">MySecretProvider</Property>
    </Flume>
  </Appenders>
  <Loggers>
    <Root level="error">
      <AppenderRef ref="eventLogger"/>
    </Root>
  </Loggers>
</Configuration>
----

A sample FlumeAppender configuration that is configured with a primary and a secondary agent compresses the body, and formats the body using RFC5424Layout and passes the events to an embedded Flume Agent.

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <Flume name="eventLogger" compress="true" type="Embedded">
      <Agent host="192.168.10.101" port="8800"/>
      <Agent host="192.168.10.102" port="8800"/>
      <RFC5424Layout enterpriseNumber="18060" includeMDC="true" appName="MyApp"/>
    </Flume>
    <Console name="STDOUT">
      <PatternLayout pattern="%d [%p] %c %m%n"/>
    </Console>
  </Appenders>
  <Loggers>
    <Logger name="EventLogger" level="info">
      <AppenderRef ref="eventLogger"/>
    </Logger>
    <Root level="warn">
      <AppenderRef ref="STDOUT"/>
    </Root>
  </Loggers>
</Configuration>
----

A sample FlumeAppender configuration that is configured with a primary and a secondary agent using Flume configuration properties compresses the body, formats the body using RFC5424Layout and passes the events to an embedded Flume Agent.

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="error" name="MyApp">
  <Appenders>
    <Flume name="eventLogger" compress="true" type="Embedded">
      <Property name="channels">file</Property>
      <Property name="channels.file.type">file</Property>
      <Property name="channels.file.checkpointDir">target/file-channel/checkpoint</Property>
      <Property name="channels.file.dataDirs">target/file-channel/data</Property>
      <Property name="sinks">agent1 agent2</Property>
      <Property name="sinks.agent1.channel">file</Property>
      <Property name="sinks.agent1.type">avro</Property>
      <Property name="sinks.agent1.hostname">192.168.10.101</Property>
      <Property name="sinks.agent1.port">8800</Property>
      <Property name="sinks.agent1.batch-size">100</Property>
      <Property name="sinks.agent2.channel">file</Property>
      <Property name="sinks.agent2.type">avro</Property>
      <Property name="sinks.agent2.hostname">192.168.10.102</Property>
      <Property name="sinks.agent2.port">8800</Property>
      <Property name="sinks.agent2.batch-size">100</Property>
      <Property name="sinkgroups">group1</Property>
      <Property name="sinkgroups.group1.sinks">agent1 agent2</Property>
      <Property name="sinkgroups.group1.processor.type">failover</Property>
      <Property name="sinkgroups.group1.processor.priority.agent1">10</Property>
      <Property name="sinkgroups.group1.processor.priority.agent2">5</Property>
      <RFC5424Layout enterpriseNumber="18060" includeMDC="true" appName="MyApp"/>
    </Flume>
    <Console name="STDOUT">
      <PatternLayout pattern="%d [%p] %c %m%n"/>
    </Console>
  </Appenders>
  <Loggers>
    <Logger name="EventLogger" level="info">
      <AppenderRef ref="eventLogger"/>
    </Logger>
    <Root level="warn">
      <AppenderRef ref="STDOUT"/>
    </Root>
  </Loggers>
</Configuration>
----

[#JDBCAppender]
=== JDBCAppender

As of Log4j 2.11.0, JDBC support has moved from the existing module
`log4j-core` to the new module `log4j-jdbc`.

The JDBC Appender configured with a `DataSource` requires JNDI support so as of release 2.17.1 this appender will not function unless `log4j2.enableJndiJdbc=true` is configured as a system property or environment variable.
See the xref:manual/systemproperties.adoc#log4j2.enableJndiJdbc[`log4j2.enableJndiJdbc`] system property.

The JDBCAppender writes log events to a relational database table using standard JDBC.
It can be configured to obtain JDBC connections using a JNDI `DataSource` or a custom factory method.
Whichever approach you take, it *_must_* be backed by a connection pool.
Otherwise, logging performance will suffer greatly.
If batch statements are supported by the configured JDBC driver and a `bufferSize` is configured to be a positive number, then log events will be batched.
Note that as of Log4j 2.8, there are two ways to configure log event to column mappings: the original `ColumnConfig` style that only allows strings and timestamps, and the new `ColumnMapping` plugin that uses Log4j's built-in type conversion to allow for more data types.

To get off the ground quickly during development, an alternative to using a connection source based on JNDI is to use the non-pooling
`DriverManager` connection source.
This connection source uses a JDBC connection string, a username, and a password.
Optionally, you can also use properties.

.JDBCAppender Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|name |String |_Required._ The name of the Appender.

|ignoreExceptions |boolean |The default is `true`, causing exceptions
encountered while appending events to be internally logged and then
ignored. When set to `false` exceptions will be propagated to the
caller, instead. You must set this to `false` when wrapping this
Appender in a <<FailoverAppender>>.

|filter |Filter |A Filter to determine if the event should be handled by
this Appender. More than one Filter may be used by using a
CompositeFilter.

|bufferSize |int |If an integer is greater than 0, this causes the appender
to buffer log events and flush whenever the buffer reaches this size.

|connectionSource |ConnectionSource |_Required._ The connection source
from which database connections should be retrieved.

|tableName |String |_Required._ The name of the database table to insert
log events into.

|columnConfigs |ColumnConfig[] |_Required (and/or columnMappings)._
Information about the columns that log event data should be inserted
into and how to insert that data. This is represented by multiple
`<Column>` elements.

|columnMappings |ColumnMapping[] |_Required (and/or columnConfigs)._ A
list of column mapping configurations. Each column must specify a column
name. Each column can have a conversion type specified by its fully
qualified class name. By default, the conversion type is `String`. If
the configured type is assignment-compatible with
link:../javadoc/log4j-api/org/apache/logging/log4j/util/ReadOnlyStringMap.html[`ReadOnlyStringMap`]
/
link:../javadoc/log4j-api/org/apache/logging/log4j/spi/ThreadContextMap.html[`ThreadContextMap`]
or
link:../javadoc/log4j-api/org/apache/logging/log4j/spi/ThreadContextStack.html[`ThreadContextStack`],
then that column will be populated with the MDC or NDC respectively
(this is database-specific how they handle inserting a `Map` or `List`
value). If the configured type is assignment-compatible with
`java.util.Date`, then the log timestamp will be converted to that
configured date type. If the configured type is assignment-compatible
with `java.sql.Clob` or `java.sql.NClob`, then the formatted event will
be set as a Clob or NClob respectively (similar to the traditional
ColumnConfig plugin). If a `literal` attribute is given, then its value
will be used as is in the `INSERT` query without any escaping.
Otherwise, the layout or pattern specified will be converted into the
configured type and stored in that column.

|immediateFail |boolean |false |When set to true, log events will not
wait to try to reconnect and will fail immediately if the JDBC resources
are not available. New in 2.11.2.

|reconnectIntervalMillis |long |5000 |If set to a value greater than 0,
after an error, the JDBCDatabaseManager will attempt to reconnect to the database
after waiting the specified number of milliseconds. If the reconnect
fails then an exception will be thrown (which can be caught by the
application if `ignoreExceptions` is set to `false`). New in 2.11.2.
|=======================================================================

When configuring the JDBCAppender, you must specify a `ConnectionSource`
implementation from which the Appender gets JDBC connections.
You must use exactly one of the following nested elements:

* <<JDBCDataSource,`<DataSource>`>>: Uses JNDI.
* <<JDBCConnectionFactory,`<ConnectionFactory>`>>: Points to a class-method pair to provide JDBC connections.
* <<JDBCDriverManager,`<DriverManager>`>>: A quick and dirty way to get off the ground, no connection pooling.
* <<JDBCPoolingDriver,`<PoolingDriver>`>>: Uses Apache Commons DBCP to provide connection pooling.

[#JDBCDataSource]
.DataSource Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|jndiName |String |_Required._ The full, prefixed JNDI name that the
`javax.sql.DataSource` is bound to, such as
`java:/comp/env/jdbc/LoggingDatabase`. The `DataSource` must be backed
by a connection pool; otherwise, logging will be very slow.
|=======================================================================

[#JDBCConnectionFactory]
.ConnectionFactory Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|class |Class |_Required._ The fully qualified name of a class
containing a static factory method for obtaining JDBC connections.

|method |Method |_Required._ The name of a static factory method for
obtaining JDBC connections. This method must have no parameters and its
return type must be either `java.sql.Connection` or `DataSource`. If the
method returns `Connection`, it must obtain them from a connection pool
(and they will be returned to the pool when Log4j is done with them);
otherwise, logging will be very slow. If the method returns a
`DataSource`, the `DataSource` will only be retrieved once, and it must
be backed by a connection pool for the same reasons.
|=======================================================================

[#JDBCDriverManager]
.DriverManager Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|connectionString |String |_Required._ The driver-specific JDBC
connection string.

|userName |String |The database user name. You cannot specify both
properties and a username or password.

|password |String |The database password. You cannot specify both
properties and a username or password.

|driverClassName |String |The JDBC driver class name. Some old JDBC
driver can only be discovered by explicitly loading them by class name.

|properties |Property[] |A list of properties. You cannot specify both
properties and a username or password.
|=======================================================================

[#JDBCPoolingDriver]
.PoolingDriver Parameters (Apache Commons DBCP)
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|DriverManager parameters |DriverManager parameters |This connection
source inherits all parameters from the DriverManager connection source.

|poolName |String |The pool name used to pool JDBC Connections. Defaults
to `example`. You can use the JDBC connection string prefix
`jdbc:apache:commons:dbcp:` followed by the pool name if you want to use
a pooled connection elsewhere. For example:
`jdbc:apache:commons:dbcp:example`.

|PoolableConnectionFactory |PoolableConnectionFactory element |Defines a PoolableConnectionFactory.
|=======================================================================

[#JDBCPoolableConnectionFactory]
.PoolableConnectionFactory Parameters (Apache Commons DBCP)
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|autoCommitOnReturn |boolean | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|cacheState |boolean | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|connectionInitSqls |Strings | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|defaultAutoCommit |Boolean | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|defaultCatalog |String | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|defaultQueryTimeoutSeconds |Integer | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|defaultReadOnly |Boolean | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|defaultTransactionIsolation |int | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|disconnectionSqlCodes |Strings | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|fastFailValidation |boolean | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|maxConnLifetimeMillis |long | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|maxOpenPreparedStatements |int | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|poolStatements |boolean | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|rollbackOnReturn |boolean | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|validationQuery |String | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|validationQueryTimeoutSeconds |int | See https://commons.apache.org/proper/commons-dbcp/configuration.html[Apache Commons DBCP configuration].
|=======================================================================

When configuring the JDBCAppender, use the nested `<Column>` elements to specify which columns in the table should be written to and how to write to them.
The JDBCAppender uses this information to formulate a
`PreparedStatement` to insert records without SQL injection vulnerability.

.Column Parameters
[width="100%",cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|name |String |_Required._ The name of the database column.

|pattern |String |Use this attribute to insert a value or values from
the log event in this column using a `PatternLayout` pattern. Simply
specify any legal pattern in this attribute. Either this attribute,
`literal`, or `isEventTimestamp="true"` must be specified, but not more
than one of these.

|literal |String |Use this attribute to insert a literal value in this
column. The value will be included directly in the insert SQL, without
any quoting (which means that if you want this to be a string, your
value should contain single quotes around it like this:
`literal="'Literal String'"`). This is especially useful for databases
that don't support identity columns. For example, if you are using
Oracle you could specify `literal="NAME_OF_YOUR_SEQUENCE.NEXTVAL"` to
insert a unique ID in an ID column. Either this attribute, `pattern`, or
`isEventTimestamp="true"` must be specified, but not more than one of
these.

|parameter |String a|
Use this attribute to insert an expression with a parameter marker '?'
in this column. The value will be included directly in the insert SQL,
without any quoting (which means that if you want this to be a string,
your value should contain single quotes around it like this:

`<ColumnMapping name="instant" parameter="TIMESTAMPADD('MILLISECOND', ?, TIMESTAMP '1970-01-01')"/>`

You can only specify one of `literal` or `parameter`.

|isEventTimestamp |boolean |Use this attribute to insert the event
timestamp in this column, which should be a SQL `datetime`. The value will
be inserted as a `java.sql.Types.TIMESTAMP`. Either this attribute
(equal to `true`), `pattern`, or `isEventTimestamp` must be specified,
but not more than one of these.

|isUnicode |boolean |This attribute is ignored unless `pattern` is
specified. If `true` or omitted (default), the value will be inserted as
unicode (`setNString` or `setNClob`). Otherwise, the value will be
inserted non-Unicode (`setString` or `setClob`).

|isClob |boolean |This attribute is ignored unless `pattern` is
specified. Use this attribute to indicate that the column stores
Character Large Objects (CLOBs). If `true`, the value will be inserted
as a CLOB (`setClob` or `setNClob`). If `false` or omitted (default),
the value will be inserted as a VARCHAR or NVARCHAR (`setString` or
`setNString`).
|=======================================================================

.ColumnMapping Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|name |String |_Required._ The name of the database column.

|pattern |String |Use this attribute to insert a value or values from
the log event in this column using a `PatternLayout` pattern. Simply
specify any legal pattern in this attribute. Either this attribute,
`literal`, or `isEventTimestamp="true"` must be specified, but not more
than one of these.

|literal |String |Use this attribute to insert a literal value in this
column. The value will be included directly in the insert SQL, without
any quoting (which means that if you want this to be a string, your
value should contain single quotes around it like this:
`literal="'Literal String'"`). This is especially useful for databases
that don't support identity columns. For example, if you are using
Oracle you could specify `literal="NAME_OF_YOUR_SEQUENCE.NEXTVAL"` to
insert a unique ID in an ID column. Either this attribute, `pattern`, or
`isEventTimestamp="true"` must be specified, but not more than one of
these.

|layout |Layout |The Layout to format the LogEvent.

|type |String |Conversion type name, a fully qualified class name.
|=======================================================================

Here are a couple of sample configurations for the JDBCAppender, as well as a sample factory implementation that uses Commons Pooling and Commons DBCP to pool database connections:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="error">
  <Appenders>
    <JDBC name="databaseAppender" tableName="dbo.application_log">
      <DataSource jndiName="java:/comp/env/jdbc/LoggingDataSource" />
      <Column name="eventDate" isEventTimestamp="true" />
      <Column name="level" pattern="%level" />
      <Column name="logger" pattern="%logger" />
      <Column name="message" pattern="%message" />
      <Column name="exception" pattern="%ex{full}" />
    </JDBC>
  </Appenders>
  <Loggers>
    <Root level="warn">
      <AppenderRef ref="databaseAppender"/>
    </Root>
  </Loggers>
</Configuration>
----

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="error">
  <Appenders>
    <JDBC name="databaseAppender" tableName="LOGGING.APPLICATION_LOG">
      <ConnectionFactory class="net.example.db.ConnectionFactory" method="getDatabaseConnection" />
      <Column name="EVENT_ID" literal="LOGGING.APPLICATION_LOG_SEQUENCE.NEXTVAL" />
      <Column name="EVENT_DATE" isEventTimestamp="true" />
      <Column name="LEVEL" pattern="%level" />
      <Column name="LOGGER" pattern="%logger" />
      <Column name="MESSAGE" pattern="%message" />
      <Column name="THROWABLE" pattern="%ex{full}" />
    </JDBC>
  </Appenders>
  <Loggers>
    <Root level="warn">
      <AppenderRef ref="databaseAppender"/>
    </Root>
  </Loggers>
</Configuration>
----

[source,java]
----
package net.example.db;

import java.sql.Connection;
import java.sql.SQLException;
import java.util.Properties;

import javax.sql.DataSource;

import org.apache.commons.dbcp.DriverManagerConnectionFactory;
import org.apache.commons.dbcp.PoolableConnection;
import org.apache.commons.dbcp.PoolableConnectionFactory;
import org.apache.commons.dbcp.PoolingDataSource;
import org.apache.commons.pool.impl.GenericObjectPool;

public class ConnectionFactory {
    private interface Singleton {
        ConnectionFactory INSTANCE = new ConnectionFactory();
    }

    private final DataSource dataSource;

    private ConnectionFactory() {
        Properties properties = new Properties();
        properties.setProperty("user", "logging");
        properties.setProperty("password", "abc123"); // or get properties from some configuration file

        GenericObjectPool<PoolableConnection> pool = new GenericObjectPool<PoolableConnection>();
        DriverManagerConnectionFactory connectionFactory = new DriverManagerConnectionFactory(
                "jdbc:mysql://example.org:3306/exampleDb", properties
        );
        new PoolableConnectionFactory(
                connectionFactory, pool, null, "SELECT 1", 3, false, false, Connection.TRANSACTION_READ_COMMITTED
        );

        this.dataSource = new PoolingDataSource(pool);
    }

    public static Connection getDatabaseConnection() throws SQLException {
        return Singleton.INSTANCE.dataSource.getConnection();
    }
}
----

This appender is xref:manual/messages.adoc#MapMessage[`MapMessage`]-aware.

The following configuration uses no layout to indicate that the appender should match the keys of a `MapMessage` to the names of
`ColumnMapping`s when setting the values of the Appender's SQL INSERT
statement. This lets you insert rows for custom values in a database
table based on a Log4j `MapMessage` instead of values from `LogEvent`.

[source,xml]
----
<Configuration status="debug">

  <Appenders>
    <Console name="STDOUT">
      <PatternLayout pattern="%C{1.} %m %level MDC%X%n"/>
    </Console>
    <Jdbc name="databaseAppender" tableName="dsLogEntry" ignoreExceptions="false">
      <DataSource jndiName="java:/comp/env/jdbc/TestDataSourceAppender" />
      <ColumnMapping name="Id" />
      <ColumnMapping name="ColumnA" />
      <ColumnMapping name="ColumnB" />
    </Jdbc>
  </Appenders>

  <Loggers>
    <Logger name="org.apache.logging.log4j.core.appender.db" level="debug" additivity="false">
      <AppenderRef ref="databaseAppender" />
    </Logger>

    <Root level="fatal">
      <AppenderRef ref="STDOUT"/>
    </Root>
  </Loggers>

</Configuration>
----

[#jms-appender]
=== [[JMSAppender]]JMS Appender

The JMS Appender sends the formatted log event to a JMS Destination.

The JMS Appender requires JNDI support so as of release 2.17.0, this appender will not function unless `log4j2.enableJndiJms=true` is configured as a system property or environment variable.
See the https://logging.apache.org/log4j/2.x/manual/configuration.html#enableJndiJms[enableJndiJms] system property.

Note that in Log4j 2.0, this appender was split into a JMSQueueAppender and a JMSTopicAppender.
Starting in Log4j 2.1, these appenders were combined into the JMS Appender, which makes no distinction between queues and topics.
However, configurations written for 2.0 that use the `<JMSQueue/>` or `<JMSTopic/>` elements will continue to work with the new `<JMS/>` configuration element.

.JMS Appender Parameters
[cols="1,1,1,3",options="header"]
|===
| Parameter Name | Type | Default | Description

| factoryBindingName
| String
| _Required_
| The name to locate in the Context that provides the
https://jakarta.ee/specifications/platform/8/apidocs/javax/jms/connectionfactory[ConnectionFactory].
This can be any subinterface of `ConnectionFactory` as well.

| factoryName
| String
| _Required_
| The fully qualified class name that should be used to define the Initial Context Factory as defined in https://docs.oracle.com/javase/{java-target-version}/docs/api/javax/naming/Context.html#INITIAL_CONTEXT_FACTORY[`INITIAL_CONTEXT_FACTORY`]. If a `factoryName` is specified without a `providerURL`, a warning message will be logged as this is likely to cause problems.

| filter
| Filter
| null
| A Filter to determine if the event should be handled by this Appender. More than one Filter may be used by using a CompositeFilter.

| layout
| Layout
| _Required_
| The Layout to use to format the LogEvent. _New since 2.9, in previous versions SerializedLayout was default._

| name
| String
| _Required_
| The name of the Appender.

| password
| String
| null
| The password to use to create the JMS connection.

| providerURL
| String
| _Required_
| The URL of the provider to use as defined by https://docs.oracle.com/javase/{java-target-version}/docs/api/javax/naming/Context.html#PROVIDER_URL[PROVIDER_URL]. From Log4j 2.17, only the `java:` protocol is supported.

| destinationBindingName
| String
| _Required_
| The name to use to locate the
https://jakarta.ee/specifications/platform/8/apidocs/javax/jms/destination[Destination].
This can be a `Queue` or `Topic`, and as such, the attribute names `queueBindingName` and `topicBindingName` are aliases to maintain compatibility with the Log4j 2.0 JMS appenders.

| securityPrincipalName
| String
| null
| The name of the identity of the Principal as specified by https://docs.oracle.com/javase/{java-target-version}/docs/api/javax/naming/Context.html#SECURITY_PRINCIPAL[SECURITY_PRINCIPAL]. If a securityPrincipalName is specified without `securityCredentials`, a warning message will be logged as this is likely to cause problems.

| securityCredentials
| String
| null
| The security credentials for the principal as specified by https://docs.oracle.com/javase/{java-target-version}/docs/api/javax/naming/Context.html#SECURITY_CREDENTIALS[SECURITY_CREDENTIALS].

| ignoreExceptions
| boolean
| true
| When `true`, exceptions caught while appending events are internally logged and then ignored. When `false` exceptions are propagated to the caller. You must set this to `false` when wrapping this Appender in a FailoverAppender.

| immediateFail
| boolean
| false
| When set to true, log events will not wait to try to reconnect and will fail immediately if the JMS resources are not available. New in 2.9.

| reconnectIntervalMillis
| long
| 5000
| If set to a value greater than 0, after an error, the JMSManager will attempt to reconnect to the broker after waiting the specified number of milliseconds. If the reconnect fails then an exception will be thrown (which can be caught by the application if `ignoreExceptions` is set to `false`). New in 2.9.

| urlPkgPrefixes
| String
| null
| A colon-separated list of package prefixes for the class name of the factory class that will create a URL context factory as defined by https://docs.oracle.com/javase/{java-target-version}/docs/api/javax/naming/Context.html#URL_PKG_PREFIXES[URL_PKG_PREFIXES].

| userName
| String
| null
| The user ID used to create the JMS connection.
|===

Here is a sample JMS Appender configuration:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <JMS name="jmsQueue" destinationBindingName="MyQueue"
         factoryBindingName="MyQueueConnectionFactory">
      <JsonLayout properties="true"/>
    </JMS>
  </Appenders>
  <Loggers>
    <Root level="error">
      <AppenderRef ref="jmsQueue"/>
    </Root>
  </Loggers>
</Configuration>
----

To map your Log4j `MapMessage` to JMS `javax.jms.MapMessage`, set the layout of the appender to `MessageLayout` with `&lt;MessageLayout /&gt;` (Since 2.9.):

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <JMS name="jmsQueue" destinationBindingName="MyQueue"
         factoryBindingName="MyQueueConnectionFactory">
      <MessageLayout />
    </JMS>
  </Appenders>
  <Loggers>
    <Root level="error">
      <AppenderRef ref="jmsQueue"/>
    </Root>
  </Loggers>
</Configuration>
----

[[JPAAppender]]
=== JPAAppender

As of Log4j 2.11.0, JPA support has moved from the existing module `log4j-core` to the new module `log4j-jpa`.

The JPAAppender writes log events to a relational database table using the Java Persistence API 2.1.
It requires the API and a provider implementation to be on the classpath.
It also requires a decorated entity configured to persist to the table desired.

If you want to use the default mappings, you can extend `org.apache.logging.log4j.core.appender.db.jpa.BasicLogEventEntity` and provide an `@Id` property.
If you want to significantly customize the mappings, you can extend `org.apache.logging.log4j.core.appender.db.jpa.AbstractLogEventWrapperEntity`.

See the Javadoc or source code for these two classes for more information and examples.

[width="100%",options="header"]
|===
|Parameter Name |Type |Description

|name
|String
|_Required._ The name of the Appender.

|ignoreExceptions
|boolean
|The default is `true`, causing exceptions encountered while appending events to be internally logged and then ignored. When set to `false` exceptions will be propagated to the caller, instead. You must set this to `false` when wrapping this Appender in a FailoverAppender.

|filter
|Filter
|A Filter to determine if the event should be handled by this Appender. More than one Filter may be used by using a CompositeFilter.

|bufferSize
|int
|If an integer is greater than 0, this causes the appender to buffer log events and flush whenever the buffer reaches this size.

|entityClassName
|String
|_Required._ The fully qualified name of the concrete LogEventWrapperEntity implementation that has JPA annotations mapping it to a database table.

|persistenceUnitName
|String
|_Required._ The name of the JPA persistence unit that should be used for persisting log events.
|===

Here is a sample configuration for the JPAAppender.
The first XML sample is the Log4j configuration file, the second is the `persistence.xml` file.
EclipseLink is assumed here, but any JPA 2.1 or higher provider will do.
You should _always_ create a _separate_ persistence unit for logging, for two reasons.
First, `<shared-cache-mode>` _must_ be set to "NONE," which is usually not desired in normal JPA usage.
Also, for performance reasons the logging entity should be isolated in its persistence unit away from all other entities and you should use a non-JTA data source.
Note that your persistence unit _must_ also contain `<class>` elements for all of the `org.apache.logging.log4j.core.appender.db.jpa.converter` converter classes.

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="error">
  <Appenders>
    <JPA name="databaseAppender" persistenceUnitName="loggingPersistenceUnit"
         entityClassName="com.example.logging.JpaLogEntity" />
  </Appenders>
  <Loggers>
    <Root level="warn">
      <AppenderRef ref="databaseAppender"/>
    </Root>
  </Loggers>
</Configuration>
----

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<persistence xmlns="http://xmlns.jcp.org/xml/ns/persistence"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/persistence
                                 http://xmlns.jcp.org/xml/ns/persistence/persistence_2_1.xsd"
             version="2.1">

  <persistence-unit name="loggingPersistenceUnit" transaction-type="RESOURCE_LOCAL">
    <provider>org.eclipse.persistence.jpa.PersistenceProvider</provider>
    <class>org.apache.logging.log4j.core.appender.db.jpa.converter.ContextMapAttributeConverter</class>
    <class>org.apache.logging.log4j.core.appender.db.jpa.converter.ContextMapJsonAttributeConverter</class>
    <class>org.apache.logging.log4j.core.appender.db.jpa.converter.ContextStackAttributeConverter</class>
    <class>org.apache.logging.log4j.core.appender.db.jpa.converter.ContextStackJsonAttributeConverter</class>
    <class>org.apache.logging.log4j.core.appender.db.jpa.converter.MarkerAttributeConverter</class>
    <class>org.apache.logging.log4j.core.appender.db.jpa.converter.MessageAttributeConverter</class>
    <class>org.apache.logging.log4j.core.appender.db.jpa.converter.StackTraceElementAttributeConverter</class>
    <class>org.apache.logging.log4j.core.appender.db.jpa.converter.ThrowableAttributeConverter</class>
    <class>com.example.logging.JpaLogEntity</class>
    <non-jta-data-source>jdbc/LoggingDataSource</non-jta-data-source>
    <shared-cache-mode>NONE</shared-cache-mode>
  </persistence-unit>

</persistence>
----

[source,java]
----
package com.example.logging;
...
@Entity
@Table(name="application_log", schema="dbo")
public class JpaLogEntity extends BasicLogEventEntity {
    private static final long serialVersionUID = 1L;
    private long id = 0L;

    public TestEntity() {
        super(null);
    }
    public TestEntity(LogEvent wrappedEvent) {
        super(wrappedEvent);
    }

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    @Column(name = "id")
    public long getId() {
        return this.id;
    }

    public void setId(final long id) {
        this.id = id;
    }

    // If you want to override the mapping of any properties mapped in BasicLogEventEntity,
    // just override the getters and re-specify the annotations.
}
----

[source,java]
----
package com.example.logging;
...
@Entity
@Table(name="application_log", schema="dbo")
public class JpaLogEntity extends AbstractLogEventWrapperEntity {
    private static final long serialVersionUID = 1L;
    private long id = 0L;

    public TestEntity() {
        super(null);
    }
    public TestEntity(final LogEvent wrappedEvent) {
        super(wrappedEvent);
    }

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    @Column(name = "logEventId")
    public long getId() {
        return this.id;
    }

    public void setId(final long id) {
        this.id = id;
    }

    @Override
    @Enumerated(EnumType.STRING)
    @Column(name = "level")
    public Level getLevel() {
        return this.getWrappedEvent().getLevel();
    }

    @Override
    @Column(name = "logger")
    public String getLoggerName() {
        return this.getWrappedEvent().getLoggerName();
    }

    @Override
    @Column(name = "message")
    @Convert(converter = MyMessageConverter.class)
    public Message getMessage() {
        return this.getWrappedEvent().getMessage();
    }
    ...
}
----

[#HttpAppender]
=== HttpAppender

The HttpAppender sends log events over HTTP.
A Layout must be provided to format the LogEvent.

It will set the `Content-Type` header according to the layout.
Additional headers can be specified with embedded Property elements.

It will also wait for a response from the server, and throw an error if no 2xx response is received.

Implemented with
https://docs.oracle.com/javase/{java-target-version}/docs/api/java/net/HttpURLConnection.html[`HttpURLConnection`].

.HttpAppender Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|name |String |The name of the Appender.

|filter |Filter |A Filter to determine if the event should be handled by
this Appender. More than one Filter may be used by using a
CompositeFilter.

|layout |Layout |The Layout to use to format the LogEvent.

|Ssl |SslConfiguration |Contains the configuration for the KeyStore and
TrustStore for https. Optional, uses Java runtime defaults if not
specified. See <<SSL>>.

|verifyHostname |boolean |Whether to verify server hostname against
certificate. Only valid for https. Optional, defaults to true

|url |string |The URL to use. The URL scheme must be "http" or "https".

|method |string |The HTTP method to use. Optional, default is "POST".

|connectTimeoutMillis |integer |The connect timeout in milliseconds.
Optional, default is 0 (infinite timeout).

|readTimeoutMillis |integer |The socket read timeout in milliseconds.
Optional, default is 0 (infinite timeout).

| [[HttpAppender-element-headers]]headers
| Property[]
| Additional HTTP headers to use.

The values support
xref:manual/configuration.adoc#lazy-property-substitution[runtime property substitution]
and are evaluated in a
xref:manual/lookups.adoc#global-context[_global context_].

|ignoreExceptions |boolean |The default is `true`, causing exceptions
encountered while appending events to be internally logged and then
ignored. When set to `false` exceptions will be propagated to the
caller, instead. You must set this to `false` when wrapping this
Appender in a <<FailoverAppender>>.
|=======================================================================

Here is a sample HttpAppender configuration snippet:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration>
  <!-- ... -->
  <Appenders>
    <Http name="Http" url="https://localhost:9200/test/log4j/">
      <Property name="X-Java-Runtime" value="$${java:runtime}" />
      <JsonTemplateLayout/>
      <SSL>
        <KeyStore   location="log4j2-keystore.jks" passwordEnvironmentVariable="KEYSTORE_PASSWORD"/>
        <TrustStore location="truststore.jks"      passwordFile="${sys:user.home}/truststore.pwd"/>
      </SSL>
    </Http>
  </Appenders>
  <!-- ... -->
</Configuration>
----

[[KafkaAppender]]
=== KafkaAppender

The KafkaAppender logs events to an https://kafka.apache.org/[Apache Kafka] topic.
Each log event is sent as a Kafka record.

[cols="1m,1m,5"]
|===
|Parameter Name |Type |Description

|topic
|String
|The Kafka topic to use. Required.

|[[KafkaAppender-attr-key]]key
|String
|The key that will be sent to Kafka with every message.

Supports
xref:manual/configuration.adoc#lazy-property-substitution[runtime property substitution]
and is evaluated in the
xref:manual/lookups.adoc#event-context[_context of the current event_].

|filter
|Filter
|A Filter to determine if the event should be handled by this Appender. More than one Filter may be used by using a CompositeFilter.

|layout
|Layout
|The Layout to use to format the LogEvent. Required, there is no default. _New since 2.9, in previous versions `<PatternLayout pattern="%m"/>` was default._

|name
|String
|The name of the Appender. Required.

|ignoreExceptions
|boolean
|The default is `true`, causing exceptions encountered while appending events to be internally logged and then ignored. When set to `false` exceptions will be propagated to the caller, instead. You must set this to `false` when wrapping this Appender in a <<FailoverAppender>>.

|syncSend
|boolean
|The default is `true`, causing sends to block until the record has been acknowledged by the Kafka server. When set to `false`, sends a return immediately, allowing for lower latency and significantly higher throughput. _New since 2.8. Be aware that this is a new addition, and it has not been extensively tested.
Any failure sending to Kafka will be reported as an error to xref:manual/status-logger.adoc[] and the log event will be dropped (the ignoreExceptions parameter will not be effective).
Log events may arrive out of order on the Kafka server._

|properties
|Property[]
|You can set properties in https://kafka.apache.org/documentation.html#producerconfigs[Kafka producer properties]. You need to set the `bootstrap.servers` property, there are sensible default values for the others. Do not set the `value.serializer` nor `key.serializer` properties.
|===

Here is a sample KafkaAppender configuration snippet:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration>
  <!-- ... -->
  <Appenders>
    <Kafka name="Kafka" topic="log-test">
      <PatternLayout pattern="%date %message"/>
      <Property name="bootstrap.servers">localhost:9092</Property>
    </Kafka>
  </Appenders>
  <!-- ... -->
</Configuration>
----

This appender is synchronous by default and will block until the record has been acknowledged by the Kafka server, timeout for this can be set with the `timeout.ms` property (defaults to 30 seconds).
Wrap with https://logging.apache.org/log4j/2.x/manual/appenders.html#AsyncAppender[Async appender] and/or set syncSend to `false` to log asynchronously.

This appender requires the https://kafka.apache.org/[Kafka client library].
Note that you need to use a version of the Kafka client library matching the Kafka server used.

_Note:_ Make sure to not let `org.apache.kafka` log to a Kafka appender on DEBUG level, since that will cause recursive logging:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration>
  <!-- ... -->
  <Loggers>
    <Root level="DEBUG">
      <AppenderRef ref="Kafka"/>
    </Root>
    <Logger name="org.apache.kafka" level="INFO" /> <!-- avoid recursive logging -->
  </Loggers>
  <!-- ... -->
</Configuration>
----

[#NoSQLAppender]
=== NoSQLAppender

The NoSQLAppender writes log events to a NoSQL database using an internal lightweight provider interface.
Provider implementations currently exist for MongoDB, and writing a custom provider is quite simple.

.NoSQLAppender Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|name |String |_Required._ The name of the Appender.

|ignoreExceptions |boolean |The default is `true`, causing exceptions
encountered while appending events to be internally logged and then
ignored. When set to `false` exceptions will be propagated to the
caller, instead. You must set this to `false` when wrapping this
Appender in a <<FailoverAppender>>.

|filter |Filter |A Filter to determine if the event should be handled by
this Appender. More than one Filter may be used by using a
CompositeFilter.

|bufferSize |int |If an integer is greater than 0, this causes the appender
to buffer log events and flush whenever the buffer reaches this size.

|NoSqlProvider |NoSQLProvider<C extends NoSQLConnection<W, T extends
NoSQLObject<W>>> |_Required._ The NoSQL provider that provides
connections to the chosen NoSQL database.
|=======================================================================

.`NoSqlAppender` -- nested elements
[cols="1m,1,4",id=NoSqlAppender-element-keyValuePairs]
|===
| Type | Multiplicity | Description

| xref:plugin-reference.adoc#org-apache-logging-log4j_log4j-core_org-apache-logging-log4j-core-util-KeyValuePair[`KeyValuePair`]
| Zero or more
a| Adds a simple key/value field to the NoSQL object.

The `value` attribute of the pair supports
xref:manual/configuration.adoc#lazy-property-substitution[runtime property substitution]
using the
xref:manual/lookups.adoc#event-context[current event as context].

|===

You specify which NoSQL provider to use by specifying the appropriate configuration element within the `<NoSql>` element.
The only type currently supported is `<MongoDb>`.
To create your custom provider, read the JavaDoc for the `NoSQLProvider`, `NoSQLConnection`, and `NoSQLObject` classes and the documentation about creating Log4j plugins.
We recommend you review the source code for the MongoDB providers as a guide for creating your provider.

The following example demonstrates how log events are persisted in NoSQL databases if represented in a JSON format:

[source,json]
----
{
    "level": "WARN",
    "loggerName": "com.example.application.MyClass",
    "message": "Something happened that you might want to know about.",
    "source": {
        "className": "com.example.application.MyClass",
        "methodName": "exampleMethod",
        "fileName": "MyClass.java",
        "lineNumber": 81
    },
    "marker": {
        "name": "SomeMarker",
        "parent" {
            "name": "SomeParentMarker"
        }
    },
    "threadName": "Thread-1",
    "millis": 1368844166761,
    "date": "2013-05-18T02:29:26.761Z",
    "thrown": {
        "type": "java.sql.SQLException",
        "message": "Could not insert record. Connection lost.",
        "stackTrace": [
                { "className": "org.example.sql.driver.PreparedStatement$1", "methodName": "responder", "fileName": "PreparedStatement.java", "lineNumber": 1049 },
                { "className": "org.example.sql.driver.PreparedStatement", "methodName": "executeUpdate", "fileName": "PreparedStatement.java", "lineNumber": 738 },
                { "className": "com.example.application.MyClass", "methodName": "exampleMethod", "fileName": "MyClass.java", "lineNumber": 81 },
                { "className": "com.example.application.MainClass", "methodName": "main", "fileName": "MainClass.java", "lineNumber": 52 }
        ],
        "cause": {
            "type": "java.io.IOException",
            "message": "Connection lost.",
            "stackTrace": [
                { "className": "java.nio.channels.SocketChannel", "methodName": "write", "fileName": null, "lineNumber": -1 },
                { "className": "org.example.sql.driver.PreparedStatement$1", "methodName": "responder", "fileName": "PreparedStatement.java", "lineNumber": 1032 },
                { "className": "org.example.sql.driver.PreparedStatement", "methodName": "executeUpdate", "fileName": "PreparedStatement.java", "lineNumber": 738 },
                { "className": "com.example.application.MyClass", "methodName": "exampleMethod", "fileName": "MyClass.java", "lineNumber": 81 },
                { "className": "com.example.application.MainClass", "methodName": "main", "fileName": "MainClass.java", "lineNumber": 52 }
            ]
        }
    },
    "contextMap": {
        "ID": "86c3a497-4e67-4eed-9d6a-2e5797324d7b",
        "username": "JohnDoe"
    },
    "contextStack": [
        "topItem",
        "anotherItem",
        "bottomItem"
    ]
}
----

[#NoSQLAppenderMongoDB]
==== NoSQL providers for MongoDB

[#mongo-installation]
===== Installation

Starting with version 2.11.0, Log4j supplies providers for the
https://www.mongodb.com/[MongoDB]
NoSQL database engine, based on the
https://www.mongodb.com/docs/drivers/java/sync/current/[MongoDB synchronous Java driver].
The choice of the provider to user depends on:

* the major version of the MongoDB Java driver your application uses: Log4j supports all major versions starting from version 2.
* the type of driver API used: either the _Legacy API_ or the _Modern API_.
See https://www.mongodb.com/docs/drivers/java/sync/current/legacy/[MongoDB documentation]
for the difference between APIs.

[NOTE]
====
The list of dependencies of your application provides a hint as to which driver API your application is using.
If your application contains any one of these dependencies, it might use the **Legacy API**:

* `org.mongodb:mongo-java-driver`
* `org.mongodb:mongodb-driver-legacy`

If you application only uses `org.mongodb:mongodb-driver-sync`, it uses the **Modern API**.
====

[WARNING]
====
The version of the MongoDB Java driver is not the same as the version of the MongoDB server.
See
https://www.mongodb.com/docs/drivers/java/sync/current/compatibility/[MongoDB compatibility matrix]
for more information.
====

In order to use a Log4j MongoDB appender you need to add the following dependencies to your application:

.MongoDB providers compatibility table
[cols="2,2,2,5"]
|===
| Driver version | Driver API | Log4j artifact | Notes

| `2.x`
| Legacy
| https://central.sonatype.com/artifact/org.apache.logging.log4j/log4j-mongodb2[`log4j-mongodb2`]
| Reached end-of-support.

Last released version: `2.12.4`

| [[NoSQLAppenderMongoDB3]]`3.x`
| Legacy
| https://central.sonatype.com/artifact/org.apache.logging.log4j/log4j-mongodb3[`log4j-mongodb3`]
| Reached end-of-support.

Last released version: `2.23.1`

| `4.x`
| Modern
| https://central.sonatype.com/artifact/org.apache.logging.log4j/log4j-mongodb4[`log4j-mongodb4`]
|

| `5.x` or later
| Modern
| https://central.sonatype.com/artifact/org.apache.logging.log4j/log4j-mongodb[`log4j-mongodb`]
|
|===

[TIP]
====
If you are note sure, which implementation to choose, `log4j-mongodb` is the recommended choice.
====

[#log4j-mongodb]
===== NoSQL provider for MongoDB (current)

This section details specializations of the
<<NoSQLAppender>> provider for MongoDB using the current MongoDB driver (version 5).
The NoSQLAppender Appender writes log events to a NoSQL database using an internal lightweight provider interface.

.MongoDB Provider Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|connection |String |_Required._ The MongoDB
http://mongodb.github.io/mongo-java-driver/5.0/apidocs/mongodb-driver-core/com/mongodb/ConnectionString.html?is-external=true"[connection string]
in the format `mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database.collection][?options]]`.

|capped |boolean |Enable support for
https://www.mongodb.com/docs/manual/core/capped-collections/[capped
collections]

|collectionSize |long |Specify the size in bytes of the capped collection
to use if enabled. The minimum size is 4096 bytes, and larger sizes will
be increased to the nearest integer multiple of 256. See the capped
collection documentation linked above for more information.
|=======================================================================

This appender is xref:manual/messages.adoc#MapMessage[MapMessage]-aware.

Here are a few sample configurations for the NoSQLAppender and MongoDB4 provider:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="WARN">
  <Appenders>
    <NoSql name="MongoDbAppender">
      <MongoDb connection="mongodb://log4jUser:12345678@localhost:${sys:MongoDBTestPort:-27017}/testDb.testCollection" />
    </NoSql>
  </Appenders>
  <Loggers>
    <Root level="ALL">
      <AppenderRef ref="MongoDbAppender" />
    </Root>
  </Loggers>
</Configuration>
----

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="WARN">
  <Appenders>
    <NoSql name="MongoDbAppender">
      <MongoDb 
        connection="mongodb://localhost:${sys:MongoDBTestPort:-27017}/testDb.testCollection" 
        capped="true" 
        collectionSize="1073741824"/>
    </NoSql>
  </Appenders>
  <Loggers>
    <Root level="ALL">
      <AppenderRef ref="MongoDbAppender" />
    </Root>
  </Loggers>
</Configuration>
----

You can define additional fields to log using KeyValuePair elements, for example:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="WARN">
    <Appenders>
        <NoSql name="MongoDbAppender">
            <MongoDb connection="mongodb://localhost:${sys:MongoDBTestPort:-27017}/testDb.testCollection" />
            <KeyValuePair key="A" value="1" />
            <KeyValuePair key="B" value="2" />
            <KeyValuePair key="env1" value="${env:PATH}" />
            <KeyValuePair key="env2" value="$${env:PATH}" />
        </NoSql>
    </Appenders>
    <Loggers>
        <Root level="ALL">
            <AppenderRef ref="MongoDbAppender" />
        </Root>
    </Loggers>
</Configuration>
----

[#log4j-mongodb4]
===== [[NoSQLAppenderMongoDB4]] NoSQL provider  for MongoDB 4 (deprecated)

The `log4j-mongodb4` module is deprecated in favor of <<log4j-mongodb,NoSQL provider for MongoDB>>.

This section details specializations of the
<<NoSQLAppender>> provider for MongoDB using the MongoDB driver version 4. The NoSQLAppender Appender writes log events to a NoSQL database using an internal lightweight provider interface.

.MongoDB Provider Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|connection |String |_Required._ The MongoDB
http://mongodb.github.io/mongo-java-driver/4.0/apidocs/mongodb-driver-core/com/mongodb/ConnectionString.html?is-external=true"[connection string]
in the format `mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database.collection][?options]]`.

|capped |boolean |Enable support for
https://www.mongodb.com/docs/manual/core/capped-collections/[capped
collections]

|collectionSize |long |Specify the size in bytes of the capped collection
to use if enabled. The minimum size is 4096 bytes, and larger sizes will
be increased to the nearest integer multiple of 256. See the capped
collection documentation linked above for more information.
|=======================================================================

This appender is xref:manual/messages.adoc#MapMessage[MapMessage]-aware.

Here are a few sample configurations for the NoSQLAppender and MongoDB4 provider:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="WARN">
  <Appenders>
    <NoSql name="MongoDbAppender">
      <MongoDb4 connection="mongodb://log4jUser:12345678@localhost:${sys:MongoDBTestPort:-27017}/testDb.testCollection" />
    </NoSql>
  </Appenders>
  <Loggers>
    <Root level="ALL">
      <AppenderRef ref="MongoDbAppender" />
    </Root>
  </Loggers>
</Configuration>
----

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="WARN">
  <Appenders>
    <NoSql name="MongoDbAppender">
      <MongoDb4 
        connection="mongodb://localhost:${sys:MongoDBTestPort:-27017}/testDb.testCollection" 
        capped="true" 
        collectionSize="1073741824"/>
    </NoSql>
  </Appenders>
  <Loggers>
    <Root level="ALL">
      <AppenderRef ref="MongoDbAppender" />
    </Root>
  </Loggers>
</Configuration>
----

You can define additional fields to log using KeyValuePair elements, for example:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="WARN">
    <Appenders>
        <NoSql name="MongoDbAppender">
            <MongoDb4 connection="mongodb://localhost:${sys:MongoDBTestPort:-27017}/testDb.testCollection" />
            <KeyValuePair key="A" value="1" />
            <KeyValuePair key="B" value="2" />
            <KeyValuePair key="env1" value="${env:PATH}" />
            <KeyValuePair key="env2" value="$${env:PATH}" />
        </NoSql>
    </Appenders>
    <Loggers>
        <Root level="ALL">
            <AppenderRef ref="MongoDbAppender" />
        </Root>
    </Loggers>
</Configuration>
----

[[NoSQLAppenderApacheCouchDB]]
=== NoSQLAppender for Apache CouchDB

This section details specializations of the <<NoSQLAppender>> provider for CouchDB.
The NoSQLAppender writes log events to a NoSQL database using an internal lightweight provider interface.

[width="100%",options="header"]
|===
|Parameter Name |Type |Description

|factoryClassName
|Class
|To provide a connection to the CouchDB database, you can use this attribute and `factoryMethodName` to specify a class and static method to retrieve the connection. The method must return an `org.lightcouch.CouchDbClient` or a `org.lightcouch.CouchDbProperties`. If you use the factory method for providing a connection, you must not specify the `databaseName`, `protocol`, `server`, `port`, `username`, or `password` attributes.

|factoryMethodName
|Method
|See the documentation for attribute `factoryClassName`.

|databaseName
|String
|If you do not specify a `factoryClassName` and `factoryMethodName` for providing a CouchDB connection, you must specify a CouchDB database name using this attribute. You must also specify a `username` and `password`. You can optionally also specify a `protocol` (defaults to `http`), `server` (defaults to localhost), and a `port` (defaults to 80 for `http` and 443 for `https`).

|protocol
|String
|Must either be "http" or "https." See the documentation for attribute `databaseName`.

|server
|String
|See the documentation for attribute `databaseName`.

|port
|int
|See the documentation for attribute `databaseName`.

|username
|String
|See the documentation for attributes `databaseName`.

|password
|String
|See the documentation for attributes `databaseName`.
|===

Here are a few sample configurations for the NoSQLAppender and CouchDB provider:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="error">
  <Appenders>
    <NoSql name="databaseAppender">
      <CouchDb databaseName="applicationDb" protocol="https" server="couch.example.org"
               username="loggingUser" password="abc123" />
    </NoSql>
  </Appenders>
  <Loggers>
    <Root level="warn">
      <AppenderRef ref="databaseAppender"/>
    </Root>
  </Loggers>
</Configuration>
----

[#servlet-appender]
=== Servlet appender

The servlet appender allows users to forward all logging calls to the
https://jakarta.ee/specifications/servlet/5.0/apidocs/jakarta/servlet/servletcontext#log(java.lang.String,java.lang.Throwable)[`ServletContext.log()`]
methods.
You can use it by declaring an appender of type `Servlet` in your configuration file:

[tabs]
====
XML::
+
[source,xml,indent=0]
----
include::example$manual/appenders/servlet-appender.xml[tag=servlet]
----

JSON::
+
[source,xml,indent=0]
----
include::example$manual/appenders/servlet-appender.json[tag=servlet]
----

YAML::
+
[source,xml,indent=0]
----
include::example$manual/appenders/servlet-appender.yaml[tag=servlet]
----

Properties::
+
[source,xml,indent=0]
----
include::example$manual/appenders/servlet-appender.properties[tag=servlet]
----
====

<1> Encodes events using xref:manual/pattern-layout.adoc[] and forwards the call to
`ServletContext.log()`.
Setting `alwaysWriteExceptions` to `false` prevents the stacktrace from appearing as both part of the `message` argument and as `throwable` argument:
this usually results in the stacktrace being printed to the log file twice.

Additional runtime dependencies are required for using the servlet appender:

include::partial$manual/dependencies-log4j-jakarta-web.adoc[]

See xref:jakarta.adoc[] for more information.

[CAUTION]
====
The `ServletContext.log(String, Throwable)` method predates modern logging APIs.
By using Servlet appender you typically will not be able to differentiate log events by log level or logger name.
====

[[SMTPAppender]]
=== SMTPAppender

Sends an e-mail when a specific logging event occurs, typically on errors or fatal errors.

The number of logging events delivered in this e-mail depends on the value of the `BufferSize` option.
The `SMTPAppender` keeps only the last `BufferSize` logging events in its cyclic buffer.
This keeps memory requirements at a reasonable level while still delivering useful application context.
All events in the buffer are included in the email.
The buffer will contain the most recent events of level TRACE to WARN preceding the event that triggered the email.

The default behavior is to trigger sending an email whenever an ERROR or higher severity event is logged and to format it as HTML.
The circumstances of when the email is sent can be controlled by setting one or more filters on the Appender.
As with other Appenders, the formatting can be controlled by specifying a Layout for the Appender.

[width="100%",options="header"]
|===
|Parameter Name |Type |Description

|name
|String
|The name of the Appender.

|from
|String
|The email address of the sender.

|replyTo
|String
|The comma-separated list of reply-to email addresses.

|to
|String
|The comma-separated list of recipient email addresses.

|cc
|String
|The comma-separated list of CC email addresses.

|bcc
|String
|The comma-separated list of BCC email addresses.

|subject
|String
|The subject of the email message.

|bufferSize
|integer
|The maximum number of log events to be buffered for inclusion in the message. Defaults to 512.

|layout
|Layout
|The Layout to use to format the LogEvent. If no layout is supplied xref:manual/layouts.adoc#HTMLLayout[HTML layout] will be used.

|filter
|Filter
|A Filter to determine if the event should be handled by this Appender. More than one Filter may be used by using a CompositeFilter.

|smtpDebug
|boolean
|When set to true turns on the session debugging on STDOUT. Defaults to false.

|smtpHost
|String
|The SMTP hostname to send to. This parameter is required.

|smtpPassword
|String
|The password required to authenticate against the SMTP server.

|smtpPort
|integer
|The SMTP port to send to.

|smtpProtocol
|String
|The SMTP transport protocol (such as "smtps", defaults to "smtp").

|smtpUsername
|String
|The username required to authenticate against the SMTP server.

|ignoreExceptions
|boolean
|The default is `true`, causing exceptions encountered while appending events to be internally logged and then ignored. When set to `false` exceptions will be propagated to the caller, instead. You must set this to `false` when wrapping this Appender in a <<FailoverAppender>>.

|SSL
|SslConfiguration
|Contains the configuration for the KeyStore and TrustStore. See <<SSL>>.
|===

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <SMTP name="Mail" subject="Error Log" to="errors@logging.apache.org" from="test@logging.apache.org"
          smtpHost="localhost" smtpPort="25" bufferSize="50">
    </SMTP>
  </Appenders>
  <Loggers>
    <Root level="error">
      <AppenderRef ref="Mail"/>
    </Root>
  </Loggers>
</Configuration>
----

[#SocketAppender]
=== SocketAppender

The `SocketAppender` is an OutputStreamAppender that writes its output to a remote destination specified by a host and port.
The data can be sent over either TCP or UDP and can be sent in any format.
You can optionally secure communication with <<SSL>>.
Note that the TCP and SSL variants write to the socket as a stream and do not expect a response from the target destination.
Due to limitations in the TCP protocol that means that when the target server closes its connection some log events may continue to appear to succeed until a closed connection exception is raised, causing those events to be lost.
If guaranteed delivery is required a protocol that requires acknowledgments must be used.

.`SocketAppender` Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|name |String |The name of the Appender.

|host |String |The name or address of the system that is listening for
log events. This parameter is required.

|port |integer |The port on the host that is listening for log events.
This parameter must be specified. If the hostname resolves to multiple
IP addresses the TCP and SSL variations will fail over to the next IP
address when a connection is lost.

|protocol |String |"TCP" (default), "SSL" or "UDP".

|SSL |SslConfiguration |Contains the configuration for the KeyStore and
TrustStore. See <<SSL>>.

|filter |Filter |A Filter to determine if the event should be handled by
this Appender. More than one Filter may be used by using a
CompositeFilter.

|immediateFail |boolean |When set to true, log events will not wait to
try to reconnect and will fail immediately if the socket is not
available.

|immediateFlush |boolean |When set to true - the default, each write
will be followed by a flush. This will guarantee the data is written to
disk but could impact performance.

|bufferedIO |boolean |When true - the default, events are written to a
buffer and the data will be written to the socket when the buffer is
full or, if immediateFlush is set when the record is written.

|bufferSize |int |When bufferedIO is true, this is the buffer size, the
default is 8192 bytes.

|layout |Layout |The Layout to use to format the LogEvent. Required,
there is no default. _New since 2.9, in previous versions
SerializedLayout was the default._

|reconnectionDelayMillis |integer |If set to a value greater than 0,
after an error, the SocketManager will attempt to reconnect to the server
after waiting for the specified number of milliseconds. If the reconnect
fails then an exception will be thrown (which can be caught by the
application if `ignoreExceptions` is set to `false`).

|connectTimeoutMillis |integer |The connect timeout in milliseconds. The
default is 0 (infinite timeout, like `Socket.connect()` methods).

|ignoreExceptions |boolean |The default is `true`, causing exceptions
encountered while appending events to be internally logged and then
ignored. When set to `false` exceptions will be propagated to the
caller, instead. You must set this to `false` when wrapping this
Appender in a <<FailoverAppender>>.
|=======================================================================

This is an unsecured TCP configuration:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <Socket name="socket" host="localhost" port="9500">
      <JsonTemplateLayout/>
    </Socket>
  </Appenders>
  <Loggers>
    <Root level="error">
      <AppenderRef ref="socket"/>
    </Root>
  </Loggers>
</Configuration>
----

This is a secured <<SSL>> configuration:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <Socket name="socket" host="localhost" port="9500">
      <JsonTemplateLayout/>
      <SSL>
        <KeyStore location="log4j2-keystore.jks" passwordEnvironmentVariable="KEYSTORE_PASSWORD"/>
        <TrustStore location="truststore.jks" passwordFile="${sys:user.home}/truststore.pwd"/>
      </SSL>
    </Socket>
  </Appenders>
  <Loggers>
    <Root level="error">
      <AppenderRef ref="socket"/>
    </Root>
  </Loggers>
</Configuration>
----

[#SSL]
==== SSL

Several appenders can be configured to use either a plain network connection or a Secure Socket Layer (SSL) connection.
This section documents the parameters available for SSL configuration.

.SSL Configuration Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|protocol |String |The SSL protocol to use, `TLS` if omitted. A single value
may enable multiple protocols, see the
https://docs.oracle.com/en/java/javase/11/docs/specs/security/standard-names.html#sslcontext-algorithms[JVM
documentation] for details.

|KeyStore |KeyStore |Contains your private keys and certificates, and
determines which authentication credentials to send to the remote host.

|TrustStore |TrustStore |Contains the CA certificates of the remote
counterparty. Determines whether the remote authentication credentials
(and thus the connection) should be trusted.
|=======================================================================

[#KeyStore]
==== KeyStore

The Keystore is meant to contain your private keys and certificates, and determines which authentication credentials to send to the remote host.

.KeyStore Configuration Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|location |String |Path to the keystore file.

|password |char[] |Plain text password to access the keystore. Cannot be
combined with either `passwordEnvironmentVariable` or `passwordFile`.

|passwordEnvironmentVariable |String |Name of an environment variable
that holds the password. Cannot be combined with either `password` or
`passwordFile`.

|passwordFile |String |Path to a file that holds the password. Cannot be
combined with either `password` or `passwordEnvironmentVariable`.

|type |String |Optional KeyStore type, e.g. `JKS`, `PKCS12`, `PKCS11`,
`BKS`, `Windows-MY/Windows-ROOT`, `KeychainStore`, etc. The default is
JKS. See also
https://docs.oracle.com/javase/{java-target-version}/docs/technotes/guides/security/StandardNames.html#KeyStore[Standard
types].

|keyManagerFactoryAlgorithm |String |Optional KeyManagerFactory
algorithm. The default is `SunX509`. See also
https://docs.oracle.com/javase/{java-target-version}/docs/technotes/guides/security/StandardNames.html#KeyManagerFactory[Standard
algorithms].
|=======================================================================

[#TrustStore]
==== TrustStore

The trust store is meant to contain the CA certificates you are willing to trust when a remote party presents its certificate.
Determines whether the remote authentication credentials (and thus the connection) should be trusted.

In some cases, they can be the same store, although it is often better practice to use distinct stores (especially when they are file-based).

.TrustStore Configuration Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|location |String |Path to the keystore file.

|password |char[] |Plain text password to access the keystore. Cannot be
combined with either `passwordEnvironmentVariable` or `passwordFile`.

|passwordEnvironmentVariable |String |Name of an environment variable
that holds the password. Cannot be combined with either `password` or
`passwordFile`.

|passwordFile |String |Path to a file that holds the password. Cannot be
combined with either `password` or `passwordEnvironmentVariable`.

|type |String |Optional KeyStore type, e.g. `JKS`, `PKCS12`, `PKCS11`,
`BKS`, `Windows-MY/Windows-ROOT`, `KeychainStore`, etc. The default is
JKS. See also
https://docs.oracle.com/javase/{java-target-version}/docs/technotes/guides/security/StandardNames.html#KeyStore[Standard
types].

|trustManagerFactoryAlgorithm |String |Optional TrustManagerFactory
algorithm. The default is `SunX509`. See also
https://docs.oracle.com/javase/{java-target-version}/docs/technotes/guides/security/StandardNames.html#TrustManagerFactory[Standard
algorithms].
|=======================================================================

[#Example]
==== Example

[source,xml]
----
<SSL>
  <KeyStore   location="log4j2-keystore.jks" passwordEnvironmentVariable="KEYSTORE_PASSWORD"/>
  <TrustStore location="truststore.jks"      passwordFile="${sys:user.home}/truststore.pwd"/>
</SSL>
----

[#SyslogAppender]
=== SyslogAppender

The `SyslogAppender` is a `SocketAppender` that writes its output to a remote destination specified by a host and port in a format that conforms with either the BSD Syslog format or the RFC 5424 format.
The data can be sent over either TCP or UDP.

.`SyslogAppender` Parameters
[cols="20%,20%,60%",options="header",]
|=======================================================================
|Parameter Name |Type |Description
|advertise |boolean |Indicates whether the appender should be
advertised.

|appName |String |The value to use as the APP-NAME in the RFC 5424
syslog record.

|charset |String |The character set to use when converting the Syslog
String to a byte array. The String must be a valid
https://docs.oracle.com/javase/{java-target-version}/docs/api/java/nio/charset/Charset.html[`Charset`].
If not specified, the default system Charset will be used.

|connectTimeoutMillis |integer |The connect timeout in milliseconds. The
default is 0 (infinite timeout, like `Socket.connect()` methods).

|enterpriseNumber |integer |The IANA enterprise number as described in
https://datatracker.ietf.org/doc/html/rfc5424#section-7.2.2[RFC 5424]

|filter |Filter |A Filter to determine if the event should be handled by
this Appender. More than one Filter may be used by using a
CompositeFilter.

|facility |String |The facility is used to try to classify the message.
The facility option must be set to one of "KERN", "USER", "MAIL",
"DAEMON", "AUTH", "SYSLOG", "LPR", "NEWS", "UUCP", "CRON", "AUTHPRIV",
"FTP", "NTP", "AUDIT", "ALERT", "CLOCK", "LOCAL0", "LOCAL1", "LOCAL2",
"LOCAL3", "LOCAL4", "LOCAL5", "LOCAL6", or "LOCAL7". These values may be
specified as upper or lowercase characters.

|format |String |If set to "RFC5424" the data will be formatted by RFC 5424.
Otherwise, it will be formatted as a BSD
Syslog record. Note that although BSD Syslog records are required to be
1024 bytes or shorter the SyslogLayout does not truncate them. The
RFC5424Layout also does not truncate records since the receiver must
accept records of up to 2048 bytes and may accept longer records.

|host |String |The name or address of the system that is listening for
log events. This parameter is required.

|id |String |The default structured data-id to use when formatting
according to RFC 5424. If the LogEvent contains a StructuredDataMessage
the id from the Message will be used instead of this value.

|ignoreExceptions |boolean |The default is `true`, causing exceptions
encountered while appending events to be internally logged and then
ignored. When set to `false` exceptions will be propagated to the
caller, instead. You must set this to `false` when wrapping this
Appender in a <<FailoverAppender>>.

|immediateFail |boolean |When set to true, log events will not wait to
try to reconnect and will fail immediately if the socket is not
available.

|immediateFlush |boolean |When set to true - the default, each write
will be followed by a flush. This will guarantee the data is written to
disk but could impact performance.

|includeMDC |boolean |Indicates whether data from the ThreadContextMap
will be included in the RFC 5424 Syslog record. Defaults to true.

|Layout |Layout |A custom layout that overrides the `format` setting.

|loggerFields |List of KeyValuePairs |Allows arbitrary PatternLayout
patterns to be included as specified ThreadContext fields; no default
specified. To use, include a `LoggerFields` nested element, containing
one or more `KeyValuePair` elements. Each `KeyValuePair` must have a key
attribute, which specifies the key name that will be used to identify
the field within the MDC Structured Data element, and a value attribute,
which specifies the PatternLayout pattern to use as the value.

|mdcExcludes |String |A comma-separated list of mdc keys that should be
excluded from the LogEvent. This is mutually exclusive with the
mdcIncludes attribute. This attribute only applies to RFC 5424 syslog
records.

|mdcIncludes |String |A comma-separated list of mdc keys that should be
included in the FlumeEvent. Any keys in the MDC not found in the list
will be excluded. This option is mutually exclusive with the mdcExcludes
attribute. This attribute only applies to RFC 5424 syslog records.

|mdcRequired |String |A comma-separated list of `mdc` keys that must be
present in the MDC. If a key is not present a LoggingException will be
thrown. This attribute only applies to RFC 5424 syslog records.

|mdcPrefix |String |A string that should be prepended to each MDC key
to distinguish it from event attributes. The default string is
`mdc:`. This attribute only applies to RFC 5424 syslog records.

|messageId |String |The default value to be used in the MSGID field of
RFC 5424 syslog records.

|name |String |The name of the Appender.

|newLine |boolean |If true, a newline will be appended to the end of the
syslog record. The default is false.

|port |integer |The port on the host that is listening for log events.
This parameter must be specified.

|protocol |String |"TCP" or "UDP". This parameter is required.

|SSL |SslConfiguration |Contains the configuration for the KeyStore and
TrustStore. See <<SSL>>.

|reconnectionDelayMillis |integer |If set to a value greater than 0,
after an error, the SocketManager will attempt to reconnect to the server
after waiting for the specified number of milliseconds. If the reconnect
fails then an exception will be thrown (which can be caught by the
application if `ignoreExceptions` is set to `false`).
|=======================================================================

A sample syslogAppender configuration that is configured with two `SyslogAppender`s, one using the BSD format and one using RFC 5424.

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <Syslog name="bsd" host="localhost" port="514" protocol="TCP"/>
    <Syslog name="RFC5424" format="RFC5424" host="localhost" port="8514"
            protocol="TCP" appName="MyApp" includeMDC="true"
            facility="LOCAL0" enterpriseNumber="18060" newLine="true"
            messageId="Audit" id="App"/>
  </Appenders>
  <Loggers>
    <Logger name="com.mycorp" level="error">
      <AppenderRef ref="RFC5424"/>
    </Logger>
    <Root level="error">
      <AppenderRef ref="bsd"/>
    </Root>
  </Loggers>
</Configuration>
----

For <<SSL>> this appender writes its output to a remote destination specified by a host and port over SSL in a format that conforms with either the BSD Syslog format or the RFC 5424 format.

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="warn" name="MyApp">
  <Appenders>
    <Syslog name="bsd" host="localhost" port="6514" protocol="SSL">
      <SSL>
        <KeyStore   location="log4j2-keystore.jks" passwordEnvironmentVariable="KEYSTORE_PASSWORD"/>
        <TrustStore location="truststore.jks"      passwordFile="${sys:user.home}/truststore.pwd"/>
      </SSL>
    </Syslog>
  </Appenders>
  <Loggers>
    <Root level="error">
      <AppenderRef ref="bsd"/>
    </Root>
  </Loggers>
</Configuration>
----

[[JeroMQAppender]]
=== ZeroMQ/JeroMQ Appender

The ZeroMQ appender uses the https://github.com/zeromq/jeromq[JeroMQ] library to send log events to one or more ZeroMQ endpoints.

This is a simple JeroMQ configuration:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<Configuration name="JeroMQAppenderTest" status="TRACE">
  <Appenders>
    <JeroMQ name="JeroMQAppender">
      <Property name="endpoint">tcp://*:5556</Property>
      <Property name="endpoint">ipc://info-topic</Property>
    </JeroMQ>
  </Appenders>
  <Loggers>
    <Root level="info">
      <AppenderRef ref="JeroMQAppender"/>
    </Root>
  </Loggers>
</Configuration>
----

The table below describes all options.
Please consult the JeroMQ and ZeroMQ documentation for details.

[width="100%",options="header"]
|===
|Parameter Name |Type |Description

|name
|String
|The name of the Appender. Required.

|Layout
|layout
|The Layout to use to format the LogEvent. If no layout is supplied the default pattern layout of "%m%n" will be used.

|Filters
|Filter
|The Filter(s) of the Appender.

|Properties
|Property[]
|One or more Property elements, named `endpoint`.

|ignoreExceptions
|boolean
|If true, exceptions will be logged and suppressed. If false errors will be logged and then passed to the application.

|affinity
|long
|The ZMQ_AFFINITY option. Defaults to 0.

|backlog
|long
|The ZMQ_BACKLOG option. Defaults to 100.

|delayAttachOnConnect
|boolean
|The ZMQ_DELAY_ATTACH_ON_CONNECT option. Defaults to false.

|identity
|byte[]
|The ZMQ_IDENTITY option. Defaults to none.

|ipv4Only
|boolean
|The ZMQ_IPV4ONLY option. Defaults to true.

|linger
|long
|The ZMQ_LINGER option. Defaults to -1.

|maxMsgSize
|long
|The ZMQ_MAXMSGSIZE option. Defaults to -1.

|rcvHwm
|long
|The ZMQ_RCVHWM option. Defaults to 1000.

|receiveBufferSize
|long
|The ZMQ_RCVBUF option. Defaults to 0.

|receiveTimeOut
|int
|The ZMQ_RCVTIMEO option. Defaults to -1.

|reconnectIVL
|long
|The ZMQ_RECONNECT_IVL option. Defaults to 100.

|reconnectIVLMax
|long
|The ZMQ_RECONNECT_IVL_MAX option. Defaults to 0.

|sendBufferSize
|long
|The ZMQ_SNDBUF option. Defaults to 0.

|sendTimeOut
|int
|The ZMQ_SNDTIMEO option. Defaults to -1.

|sndHwm
|long
|The ZMQ_SNDHWM option. Defaults to 1000.

|tcpKeepAlive
|int
|The ZMQ_TCP_KEEPALIVE option. Defaults to -1.

|tcpKeepAliveCount
|long
|The ZMQ_TCP_KEEPALIVE_CNT option. Defaults to -1.

|tcpKeepAliveIdle
|long
|The ZMQ_TCP_KEEPALIVE_IDLE option. Defaults to -1.

|tcpKeepAliveInterval
|long
|The ZMQ_TCP_KEEPALIVE_INTVL option. Defaults to -1.

|xpubVerbose
|boolean
|The ZMQ_XPUB_VERBOSE option. Defaults to false.
|===

[#extending]
== Extending

Appenders are xref:manual/plugins.adoc[plugins] implementing link:../javadoc/log4j-core/org/apache/logging/log4j/core/Appender.html[the `Appender` interface].
This section will guide you on how to create custom ones.

[WARNING]
====
*Implementing a reliable and efficient appender is a difficult task!*
We strongly advise you to

. Use existing appenders and/or managers whenever appropriate
. Share your use case and ask for feedback in a {logging-services-url}/support.html[user support channel]
====

[#extending-plugins]
=== Plugin preliminaries

include::partial$manual/plugin-preliminaries.adoc[]

[#extending-appenders]
=== Extending appenders

Appenders are xref:manual/plugins.adoc[plugins] implementing link:../javadoc/log4j-core/org/apache/logging/log4j/core/Appender.html[the `Appender` interface].
We recommend users to extend from link:../javadoc/log4j-core/org/apache/logging/log4j/core/appender/AbstractAppender.html[`AbstractAppender`], which provides implementation convenience.
While annotating your appender with `@Plugin`, you need to make sure that

* It has a unique `name` attribute across all available `Appender` plugins
* The `category` attribute is set to link:../javadoc/log4j-core/org/apache/logging/log4j/core/config/Node.html#CATEGORY[`Node.CATEGORY`]

Most appender implementation use *managers*, which model an abstraction owning the resources, such as an `OutputStream` or a socket.
When a reconfiguration occurs a new appender will be created.
However, if nothing significant in the previous manager has changed, the new appender will simply reference it instead of creating a new one.
This ensures that events are not lost while a reconfiguration is taking place without requiring that logging pause while the reconfiguration takes place.
You are strongly advised to study the manager concept in <<collection,the predefined appenders>>, and either use an existing manager, or create your own.

You can check out following files for examples:

* {project-github-url}/log4j-core/src/main/java/org/apache/logging/log4j/core/appender/HttpAppender.java[`HttpAppender.java`]  <<HttpAppender>> sends log events over HTTP using `HttpURLConnectionManager`
* {project-github-url}/log4j-core/src/main/java/org/apache/logging/log4j/core/appender/ConsoleAppender.java[`ConsoleAppender.java`]  <<ConsoleAppender>> writes log events to either `System.out` or `System.err` using `OutputStreamManager`
